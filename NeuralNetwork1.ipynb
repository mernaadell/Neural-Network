{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs \n",
      " [[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 1]]\n",
      "\n",
      "weights1 \n",
      " [[0.23036568 0.86711733 0.33593312 0.78255256]\n",
      " [0.19200426 0.30893681 0.66330129 0.23983724]\n",
      " [0.00792779 0.14131688 0.67088578 0.93424033]]\n",
      "\n",
      "weights2 \n",
      " [[0.9024216 ]\n",
      " [0.03100725]\n",
      " [0.95473177]\n",
      " [0.11644163]]\n",
      "\n",
      "y \n",
      " [[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "\n",
      "output \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "layer 1 \n",
      " [[0.50198194 0.53527054 0.66170147 0.71793476]\n",
      " [0.54981718 0.61069955 0.79153238 0.76388127]\n",
      " [0.55929306 0.73271361 0.73239714 0.84771528]\n",
      " [0.60594476 0.78874398 0.84159184 0.87616779]]\n",
      "\n",
      "output \n",
      " [[0.76583514]\n",
      " [0.79571934]\n",
      " [0.79007702]\n",
      " [0.81408744]]\n",
      "d_weights1 \n",
      " [[-0.03760947 -0.00085032 -0.0183349  -0.00206649]\n",
      " [-0.03826418 -0.0007836  -0.02090227 -0.00171843]\n",
      " [-0.08474301 -0.00247939 -0.06657621 -0.00714857]]\n",
      "layer 1 \n",
      " [[0.48080563 0.53465373 0.64664165 0.71648489]\n",
      " [0.51922174 0.60992351 0.77672958 0.76227821]\n",
      " [0.52895282 0.732061   0.71543067 0.84652185]\n",
      " [0.56701461 0.78805778 0.82697048 0.87497665]]\n",
      "\n",
      "output \n",
      " [[0.62571732]\n",
      " [0.64621466]\n",
      " [0.62847357]\n",
      " [0.64771936]]\n",
      "d_weights1 \n",
      " [[-0.0202654   0.00335628 -0.00466655  0.00183058]\n",
      " [-0.02223218  0.00238142 -0.00953067  0.00056482]\n",
      " [-0.04290613  0.01089    -0.0307062   0.00747907]]\n",
      "layer 1 \n",
      " [[0.47010536 0.5373621  0.63959422 0.71800169]\n",
      " [0.5029466  0.61307636 0.76967406 0.76373277]\n",
      " [0.5131893  0.73484612 0.70817461 0.84772749]\n",
      " [0.54593941 0.79082168 0.82045061 0.87605285]]\n",
      "\n",
      "output \n",
      " [[0.52250992]\n",
      " [0.53118564]\n",
      " [0.50545411]\n",
      " [0.51554471]]\n",
      "d_weights1 \n",
      " [[-0.0011546  -0.00213375  0.00638221 -0.00152313]\n",
      " [-0.00304935 -0.00489487  0.00167653 -0.00546043]\n",
      " [-0.00482383  0.00147541 -0.00269039  0.00258368]]\n",
      "layer 1 \n",
      " [[0.46890389 0.53772887 0.63897381 0.71852452]\n",
      " [0.50097834 0.6122649  0.76949428 0.76321328]\n",
      " [0.51169563 0.73471782 0.70893698 0.84786434]\n",
      " [0.54370061 0.78990157 0.82124007 0.8755743 ]]\n",
      "\n",
      "output \n",
      " [[0.50926172]\n",
      " [0.51657747]\n",
      " [0.49006028]\n",
      " [0.49895221]]\n",
      "d_weights1 \n",
      " [[ 9.65009266e-04 -3.32349299e-03  7.37242173e-03 -2.33703202e-03]\n",
      " [-8.25422430e-04 -6.39339040e-03  2.86354092e-03 -6.75032404e-03]\n",
      " [-6.67647169e-04 -9.31351765e-04  3.37562791e-05  8.82014855e-04]]\n",
      "layer 1 \n",
      " [[0.46873763 0.53749735 0.6389816  0.71870287]\n",
      " [0.50060507 0.61052461 0.77000778 0.76215113]\n",
      " [0.51176992 0.73388769 0.71046285 0.84767656]\n",
      " [0.5435696  0.78812896 0.82274274 0.87467762]]\n",
      "\n",
      "output \n",
      " [[0.50863531]\n",
      " [0.51620783]\n",
      " [0.48970689]\n",
      " [0.49868656]]\n",
      "d_weights1 \n",
      " [[ 0.00099714 -0.00327348  0.00741677 -0.00230219]\n",
      " [-0.00077732 -0.00633783  0.00296243 -0.00677317]\n",
      " [-0.00055654 -0.00097264  0.00011229  0.00082112]]\n",
      "layer 1 \n",
      " [[0.46859904 0.53725555 0.6390075  0.71886885]\n",
      " [0.50027161 0.60878489 0.77055185 0.76107048]\n",
      " [0.51188001 0.73305762 0.71200916 0.84748523]\n",
      " [0.54348606 0.78635625 0.82426761 0.87377001]]\n",
      "\n",
      "output \n",
      " [[0.5083187 ]\n",
      " [0.51618877]\n",
      " [0.48971333]\n",
      " [0.49881506]]\n",
      "d_weights1 \n",
      " [[ 0.00098089 -0.00319453  0.00744328 -0.00224591]\n",
      " [-0.00078075 -0.00624572  0.0030373  -0.0067651 ]\n",
      " [-0.00054064 -0.00095356  0.00012934  0.00080358]]\n",
      "layer 1 \n",
      " [[0.46846441 0.53701847 0.63903734 0.71903122]\n",
      " [0.49994126 0.60706894 0.77111123 0.75998474]\n",
      " [0.51199001 0.73224512 0.71355944 0.84729871]\n",
      " [0.54340158 0.78460489 0.82579918 0.87286199]]\n",
      "\n",
      "output \n",
      " [[0.50801361]\n",
      " [0.51618432]\n",
      " [0.48972488]\n",
      " [0.49895281]]\n",
      "d_weights1 \n",
      " [[ 0.00096391 -0.00311712  0.0074726  -0.00218925]\n",
      " [-0.00078582 -0.00615523  0.0031125  -0.00675743]\n",
      " [-0.00052767 -0.00093283  0.00014415  0.00078789]]\n",
      "layer 1 \n",
      " [[0.46833302 0.53678654 0.63907059 0.71919037]\n",
      " [0.49961289 0.6053769  0.77168552 0.75889416]\n",
      " [0.51209901 0.73145033 0.71511371 0.8471173 ]\n",
      " [0.54331484 0.7828752  0.82733724 0.87195381]]\n",
      "\n",
      "output \n",
      " [[0.50771266]\n",
      " [0.51618654]\n",
      " [0.48973325]\n",
      " [0.49909084]]\n",
      "d_weights1 \n",
      " [[ 0.00094727 -0.0030419   0.00750524 -0.00213269]\n",
      " [-0.00079136 -0.00606719  0.0031887  -0.00675093]\n",
      " [-0.00051543 -0.00091186  0.00015814  0.00077305]]\n",
      "layer 1 \n",
      " [[0.46820468 0.5365598  0.63910706 0.71934646]\n",
      " [0.49928619 0.60370841 0.77227466 0.75779867]\n",
      " [0.51220691 0.73067298 0.71667237 0.84694114]\n",
      " [0.54322563 0.781167   0.82888197 0.87104553]]\n",
      "\n",
      "output \n",
      " [[0.50741534]\n",
      " [0.51619522]\n",
      " [0.48973834]\n",
      " [0.4992291 ]]\n",
      "d_weights1 \n",
      " [[ 0.000931   -0.00296877  0.00754122 -0.00207617]\n",
      " [-0.00079733 -0.00598151  0.00326601 -0.00674561]\n",
      " [-0.00050387 -0.00089071  0.00017135  0.00075902]]\n",
      "layer 1 \n",
      " [[0.46807923 0.5363383  0.63914658 0.71949967]\n",
      " [0.49896089 0.60206311 0.77287861 0.7566982 ]\n",
      " [0.51231363 0.7299128  0.71823581 0.84677031]\n",
      " [0.54313377 0.77948008 0.83043351 0.87013717]]\n",
      "\n",
      "output \n",
      " [[0.50712131]\n",
      " [0.51621034]\n",
      " [0.48974019]\n",
      " [0.49936771]]\n",
      "d_weights1 \n",
      " [[ 0.00091506 -0.00289765  0.00758054 -0.00201968]\n",
      " [-0.00080374 -0.00589811  0.00334452 -0.0067415 ]\n",
      " [-0.00049296 -0.00086939  0.00018379  0.00074579]]\n",
      "[[0.50712131]\n",
      " [0.51621034]\n",
      " [0.48974019]\n",
      " [0.49936771]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "neuron = 4\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+ np.exp(-x))\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, x, y):\n",
    "        self.input = x \n",
    "        print('inputs \\n' , self.input)\n",
    "        print()\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],neuron) #from x matrix 3x4 becouse 3 features\n",
    "        print('weights1 \\n',self.weights1) #for first layer\n",
    "        print()\n",
    "        self.weights2 = np.random.rand(neuron,1) # 1 3shan da l output w tale3 mn 4 neuron\n",
    "        print('weights2 \\n',self.weights2)\n",
    "        print()\n",
    "        self.y = y\n",
    "        print('y \\n',self.y)\n",
    "        print()\n",
    "        self.output = np.zeros(self.y.shape) # y hat\n",
    "        print('output \\n',self.output)  # bnfs shape l y\n",
    "    \n",
    "\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        print('layer 1 \\n',self.layer1) #\n",
    "        print() #\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "        print('output \\n',self.output) #\n",
    "\n",
    "\n",
    "    def backprop(self):\n",
    "        #application of the chain rule to find derivative of the loss function with respect to \n",
    "        #weights2 and weights1\n",
    "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) *\n",
    "                    sigmoid_derivative(self.output)))\n",
    "         #print('d_weights2 \\n',d_weights2 )\n",
    "         # )(print\n",
    "        d_weights1 = np.dot(self.input.T,\n",
    "             np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output),\n",
    "                    self.weights2.T) * sigmoid_derivative(self.layer1))\n",
    "        print('d_weights1 \\n',d_weights1) #\n",
    "        \n",
    "        # update the weights with the derivative (slope) of the loss function\n",
    "        self.weights1 += d_weights1\n",
    "        self.weights2 += d_weights2\n",
    "           \n",
    "X = np.array([[0,0,1],\n",
    "                    [0,1,1],\n",
    "                    [1,0,1],\n",
    "                    [1,1,1]])\n",
    "\n",
    "\n",
    "y = np.array([[0],\n",
    "                [1], \n",
    "                [1],\n",
    "                [0]])\n",
    "\n",
    "nn = NeuralNetwork(X,y)\n",
    "for i in range(10):\n",
    "    nn.feedforward()\n",
    "    nn.backprop()\n",
    "\n",
    "print(nn.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
